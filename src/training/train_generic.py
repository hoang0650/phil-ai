import yaml
import argparse
import torch
import os
from dotenv import load_dotenv
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments, WhisperForConditionalGeneration, WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments
from datasets import load_dataset, Audio, concatenate_datasets
from peft import LoraConfig, get_peft_model

load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")

def train(config_path):
    with open(config_path, 'r') as f: cfg = yaml.safe_load(f)
    print(f"\n>>> ðŸš€ STARTING TRAINING: {cfg['new_model_name']}")

    # ==========================================
    # CASE 1: TRAIN LLM (DEEPSEEK / QWEN)
    # ==========================================
    if "DeepSeek" in cfg['base_model'] or "Llama" in cfg['base_model']:
        print(">>> Mode: LLM Fine-Tuning (Unsloth Optimized)")
        
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name=cfg['base_model'],
            max_seq_length=cfg['max_seq_length'],
            dtype=None, 
            load_in_4bit=cfg['load_in_4bit']
        )
        
        model = FastLanguageModel.get_peft_model(
            model, r=cfg['lora_rank'], target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
            lora_alpha=16, bias="none", use_gradient_checkpointing="unsloth", random_state=3407,
        )

        # Load Datasets
        dataset_list = []
        if os.path.exists(cfg['dataset_path']):
            ds_main = load_dataset("json", data_files=cfg['dataset_path'], split="train")
            dataset_list.append(ds_main)
        
        identity_file = "data/processed/phil_identity.jsonl"
        if os.path.exists(identity_file):
            ds_identity = load_dataset("json", data_files=identity_file, split="train")
            dataset_list.append(ds_identity)

        if not dataset_list:
            raise ValueError("No datasets found for training!")
            
        dataset = concatenate_datasets(dataset_list).shuffle(seed=42)

        def format_prompts(examples):
            texts = []
            for inst, out in zip(examples["instruction"], examples["output"]):
                text = f"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{inst}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n{out}<|eot_id|>"
                texts.append(text)
            return {"text": texts}
        dataset = dataset.map(format_prompts, batched=True)

        trainer = SFTTrainer(
            model=model, tokenizer=tokenizer, train_dataset=dataset, dataset_text_field="text",
            max_seq_length=cfg['max_seq_length'],
            args=TrainingArguments(
                per_device_train_batch_size=cfg['batch_size'], gradient_accumulation_steps=cfg['grad_accum'],
                max_steps=cfg['steps'], learning_rate=cfg['learning_rate'], fp16=not torch.cuda.is_bf16_supported(),
                bf16=torch.cuda.is_bf16_supported(), logging_steps=1, output_dir="outputs", optim="paged_adamw_8bit",
                report_to="none"
            )
        )
        trainer.train()
        
        output_model_id = f"{cfg['hf_username']}/{cfg['new_model_name']}"
        print(f">>> Saving & Uploading LLM to {output_model_id}...")
        model.push_to_hub_merged(output_model_id, tokenizer, save_method="merged_4bit_forced", token=HF_TOKEN)

    # ==========================================
    # CASE 2: TRAIN WHISPER (STT)
    # ==========================================
    elif "whisper" in cfg['base_model']:
        print(">>> Mode: Whisper Fine-Tuning")
        model = WhisperForConditionalGeneration.from_pretrained(cfg['base_model'], load_in_8bit=True, device_map="auto")
        processor = WhisperProcessor.from_pretrained(cfg['base_model'], language=cfg['language'], task="transcribe")
        
        dataset = load_dataset(cfg['dataset_name'], cfg['dataset_subset'], split="train", trust_remote_code=True)
        dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
        
        def prepare_dataset(batch):
            audio = batch["audio"]
            batch["input_features"] = processor.feature_extractor(audio["array"], sampling_rate=16000).input_features[0]
            batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
            return batch
        
        dataset = dataset.map(prepare_dataset, num_proc=1)
        model = get_peft_model(model, LoraConfig(r=32, lora_alpha=64, target_modules=["q_proj", "v_proj"], bias="none"))

        trainer = Seq2SeqTrainer(
            model=model,
            args=Seq2SeqTrainingArguments(
                output_dir="outputs_whisper", per_device_train_batch_size=cfg['batch_size'],
                gradient_accumulation_steps=cfg['grad_accum'], max_steps=cfg['steps'], learning_rate=cfg['learning_rate'],
                fp16=True, predict_with_generate=True, report_to="none"
            ),
            train_dataset=dataset, tokenizer=processor.feature_extractor
        )
        trainer.train()
        
        output_model_id = f"{cfg['hf_username']}/{cfg['new_model_name']}"
        print(f">>> Uploading Whisper to {output_model_id}...")
        model.push_to_hub(output_model_id, token=HF_TOKEN)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True)
    args = parser.parse_args()
    train(args.config)